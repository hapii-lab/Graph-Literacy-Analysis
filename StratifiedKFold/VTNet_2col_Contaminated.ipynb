{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import autograd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import DataLoader, Dataset, random_split, Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "MANUAL_SEED = 1\n",
    "HIDDEN_SIZE = 256\n",
    "INPUT_SIZE = 2  # FPOGX + FPOGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "533051b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA device(s):\n",
      "CUDA:0 - NVIDIA GeForce RTX 5090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    print(f\"Found {num_devices} CUDA device(s):\")\n",
    "    for i in range(num_devices):\n",
    "        print(f\"CUDA:{i} - {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e5ce0",
   "metadata": {},
   "source": [
    "Here, a custom class is used to process the scanpath (.png) images and separate them into their respective classes (literate/illiterate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScanpathDataset(Dataset):\n",
    "    def __init__(self, img_root, seq_root, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.label_map = {\"literate\": 0, \"illiterate\": 1}\n",
    "\n",
    "        for label_name, label in self.label_map.items():\n",
    "            img_dir = os.path.join(img_root, label_name)\n",
    "            seq_dir = os.path.join(seq_root, label_name)\n",
    "\n",
    "            for img_path in glob.glob(os.path.join(img_dir, \"*.png\")):\n",
    "                base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                csv_path = os.path.join(seq_dir, base + \".csv\")\n",
    "                if os.path.exists(csv_path):\n",
    "                    self.samples.append((img_path, csv_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        from PIL import Image\n",
    "        img_path, seq_path, label = self.samples[idx]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        df = pd.read_csv(seq_path)\n",
    "\n",
    "        if \"FPOGX\" not in df.columns or \"FPOGY\" not in df.columns:\n",
    "            raise ValueError(f\"CSV file {seq_path} missing FPOGX/FPOGY columns!\")\n",
    "\n",
    "        seq = df[[\"FPOGX\", \"FPOGY\"]].values\n",
    "        seq = torch.tensor(seq, dtype=torch.float32)\n",
    "\n",
    "        return img, seq, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620d5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images, seqs, labels = zip(*batch)\n",
    "\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    seq_lengths = torch.tensor([len(seq) for seq in seqs])\n",
    "    padded_seqs = pad_sequence(seqs, batch_first=True)\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return images, padded_seqs, seq_lengths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e612949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VTNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size=2,\n",
    "                 rnn_hidden_size=256,\n",
    "                 output_size=2,\n",
    "                 rnn_type='gru',\n",
    "                 rnn_num_layers=1,\n",
    "                 n_channels_1=6,\n",
    "                 kernel_size_1=5,\n",
    "                 n_channels_2=16,\n",
    "                 kernel_size_2=5,\n",
    "                 img_n_vert=150,\n",
    "                 img_n_hor=150):\n",
    "        super(VTNet, self).__init__()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "        self.n_channels_2 = n_channels_2\n",
    "\n",
    "        # --- CNN branch ---\n",
    "        self.conv1 = nn.Conv2d(1, n_channels_1, kernel_size=kernel_size_1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(n_channels_1, n_channels_2, kernel_size=kernel_size_2)\n",
    "\n",
    "        # calculate CNN output size\n",
    "        conv1_out_vert = img_n_vert - kernel_size_1 + 1\n",
    "        conv1_out_hor = img_n_hor - kernel_size_1 + 1\n",
    "        mp1_out_vert = (conv1_out_vert - 2) // 2 + 1\n",
    "        mp1_out_hor = (conv1_out_hor - 2) // 2 + 1\n",
    "        conv2_out_vert = mp1_out_vert - kernel_size_2 + 1\n",
    "        conv2_out_hor = mp1_out_hor - kernel_size_2 + 1\n",
    "        mp2_out_vert = (conv2_out_vert - 2) // 2 + 1\n",
    "        mp2_out_hor = (conv2_out_hor - 2) // 2 + 1\n",
    "\n",
    "        self.fc1 = nn.Linear(n_channels_2 * mp2_out_hor * mp2_out_vert, 50)\n",
    "        self.fc2 = nn.Linear(rnn_hidden_size + 50, 20)\n",
    "        # --- Attention projection layers ---\n",
    "        # project CNN features -> query, and RNN outputs -> keys/values\n",
    "        self.attn_query = nn.Linear(50, rnn_hidden_size)\n",
    "        self.attn_key = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.attn_value = nn.Linear(rnn_hidden_size, rnn_hidden_size)\n",
    "        self.fc3 = nn.Linear(20, output_size)\n",
    "\n",
    "        # --- RNN branch ---\n",
    "        if rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(input_size=input_size, hidden_size=rnn_hidden_size,\n",
    "                              num_layers=rnn_num_layers, batch_first=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size=input_size, hidden_size=rnn_hidden_size,\n",
    "                               num_layers=rnn_num_layers, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(input_size=input_size, hidden_size=rnn_hidden_size,\n",
    "                              num_layers=rnn_num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, scan_path, time_series, seq_lengths):\n",
    "        # --- CNN branch ---\n",
    "        x1 = self.pool(F.relu(self.conv1(scan_path)))\n",
    "        x1 = self.pool(F.relu(self.conv2(x1)))\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x1 = F.relu(self.fc1(x1))\n",
    "\n",
    "        # --- RNN branch ---\n",
    "        packed = pack_padded_sequence(time_series, seq_lengths.cpu(),\n",
    "                                      batch_first=True, enforce_sorted=False)\n",
    "        packed_out, hidden = self.rnn(packed)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "\n",
    "        # --- Attention mechanism ---\n",
    "        # out: (B, T, H) where H = rnn_hidden_size\n",
    "        # We'll compute dot-product attention: query from CNN features, keys/values from RNN outputs\n",
    "        # Project query (from CNN) to rnn_hidden_size\n",
    "        # query: (B, H)\n",
    "        query = self.attn_query(x1)  # (B, H)\n",
    "\n",
    "        # keys, values: project RNN outputs\n",
    "        # keys/values: (B, T, H)\n",
    "        keys = self.attn_key(out)\n",
    "        values = self.attn_value(out)\n",
    "\n",
    "        # compute attention scores: (B, T)\n",
    "        scores = torch.bmm(query.unsqueeze(1), keys.transpose(1, 2)).squeeze(1)\n",
    "\n",
    "        # create mask for padded positions: (B, T)\n",
    "        max_len = out.size(1)\n",
    "        device = out.device\n",
    "        seq_range = torch.arange(0, max_len, device=device).unsqueeze(0)  # (1, T)\n",
    "        seq_lengths_exp = seq_lengths.unsqueeze(1)\n",
    "        mask = seq_range >= seq_lengths_exp  # True where padding\n",
    "\n",
    "        # apply mask: set scores at padding positions to large negative value\n",
    "        scores = scores.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        attn_weights = F.softmax(scores, dim=1)  # (B, T)\n",
    "\n",
    "        # weighted sum of values: (B, T, H) * (B, T, 1) -> (B, H)\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), values).squeeze(1)\n",
    "\n",
    "        # --- combine CNN + attention-context ---\n",
    "        x = torch.cat((x1, context), 1)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e732bd",
   "metadata": {},
   "source": [
    "## VTNet Model with Attention Mechanism\n",
    "\n",
    "This model combines:\n",
    "- **CNN branch**: Extracts spatial features from scanpath images (visual patterns)\n",
    "- **RNN branch**: Processes temporal sequences of eye movements (FPOGX, FPOGY)\n",
    "- **Attention mechanism**: Uses CNN features as query to selectively attend to important timesteps in the RNN sequence\n",
    "\n",
    "The attention allows the model to identify which temporal patterns in eye movements are most relevant given the overall spatial scanpath pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6149f2f",
   "metadata": {},
   "source": [
    "## Training Configuration 1: Cross-Validation on Full Dataset\n",
    "\n",
    "This section performs 10-fold stratified cross-validation on the complete dataset from **Scanpaths/all** and **Raw Data/all**. This provides robust performance estimates across different data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e66ee9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1499\n",
      "\n",
      "========== Fold 1/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6894 | Train Acc: 54.26%\n",
      "Epoch [2/50] | Train Loss: 0.6830 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6768 | Train Acc: 57.08%\n",
      "Epoch [4/50] | Train Loss: 0.6575 | Train Acc: 60.34%\n",
      "Epoch [5/50] | Train Loss: 0.6277 | Train Acc: 64.49%\n",
      "Epoch [6/50] | Train Loss: 0.6066 | Train Acc: 67.53%\n",
      "Epoch [7/50] | Train Loss: 0.5738 | Train Acc: 71.46%\n",
      "Epoch [8/50] | Train Loss: 0.5406 | Train Acc: 73.54%\n",
      "Epoch [9/50] | Train Loss: 0.5092 | Train Acc: 77.17%\n",
      "Epoch [10/50] | Train Loss: 0.4822 | Train Acc: 77.98%\n",
      "Epoch [11/50] | Train Loss: 0.4511 | Train Acc: 81.47%\n",
      "Epoch [12/50] | Train Loss: 0.4154 | Train Acc: 81.84%\n",
      "Epoch [13/50] | Train Loss: 0.3979 | Train Acc: 83.02%\n",
      "Epoch [14/50] | Train Loss: 0.3598 | Train Acc: 85.03%\n",
      "Epoch [15/50] | Train Loss: 0.3294 | Train Acc: 86.88%\n",
      "Epoch [16/50] | Train Loss: 0.3093 | Train Acc: 86.95%\n",
      "Epoch [17/50] | Train Loss: 0.2752 | Train Acc: 89.47%\n",
      "Epoch [18/50] | Train Loss: 0.2398 | Train Acc: 90.81%\n",
      "Epoch [19/50] | Train Loss: 0.2169 | Train Acc: 92.07%\n",
      "Epoch [20/50] | Train Loss: 0.1694 | Train Acc: 94.07%\n",
      "Epoch [21/50] | Train Loss: 0.1595 | Train Acc: 94.22%\n",
      "Epoch [22/50] | Train Loss: 0.1162 | Train Acc: 96.22%\n",
      "Epoch [23/50] | Train Loss: 0.1207 | Train Acc: 95.92%\n",
      "Epoch [24/50] | Train Loss: 0.0817 | Train Acc: 97.63%\n",
      "Epoch [25/50] | Train Loss: 0.0854 | Train Acc: 97.33%\n",
      "Epoch [26/50] | Train Loss: 0.0814 | Train Acc: 97.26%\n",
      "Epoch [27/50] | Train Loss: 0.0461 | Train Acc: 98.96%\n",
      "Epoch [28/50] | Train Loss: 0.0539 | Train Acc: 98.52%\n",
      "Epoch [29/50] | Train Loss: 0.0450 | Train Acc: 98.59%\n",
      "Epoch [30/50] | Train Loss: 0.0503 | Train Acc: 98.67%\n",
      "Epoch [31/50] | Train Loss: 0.0364 | Train Acc: 98.96%\n",
      "Epoch [32/50] | Train Loss: 0.0376 | Train Acc: 98.96%\n",
      "Epoch [33/50] | Train Loss: 0.0305 | Train Acc: 99.26%\n",
      "Epoch [34/50] | Train Loss: 0.0155 | Train Acc: 99.70%\n",
      "Epoch [35/50] | Train Loss: 0.0118 | Train Acc: 99.85%\n",
      "Epoch [36/50] | Train Loss: 0.0114 | Train Acc: 99.85%\n",
      "Epoch [37/50] | Train Loss: 0.0106 | Train Acc: 99.85%\n",
      "Epoch [38/50] | Train Loss: 0.0101 | Train Acc: 99.85%\n",
      "Epoch [39/50] | Train Loss: 0.0389 | Train Acc: 99.04%\n",
      "Epoch [40/50] | Train Loss: 0.0616 | Train Acc: 97.63%\n",
      "Epoch [41/50] | Train Loss: 0.0158 | Train Acc: 99.63%\n",
      "Epoch [42/50] | Train Loss: 0.0233 | Train Acc: 99.56%\n",
      "Epoch [43/50] | Train Loss: 0.0063 | Train Acc: 99.93%\n",
      "Epoch [44/50] | Train Loss: 0.0058 | Train Acc: 99.93%\n",
      "Epoch [45/50] | Train Loss: 0.0056 | Train Acc: 99.93%\n",
      "Epoch [46/50] | Train Loss: 0.0055 | Train Acc: 99.93%\n",
      "Epoch [47/50] | Train Loss: 0.0054 | Train Acc: 99.93%\n",
      "Epoch [48/50] | Train Loss: 0.0053 | Train Acc: 99.93%\n",
      "Epoch [49/50] | Train Loss: 0.0052 | Train Acc: 99.93%\n",
      "Epoch [50/50] | Train Loss: 0.0051 | Train Acc: 99.93%\n",
      "Fold 1 Results -> Acc: 0.833, Precision: 0.831, Recall: 0.829, F1: 0.830\n",
      "\n",
      "========== Fold 2/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6866 | Train Acc: 56.63%\n",
      "Epoch [2/50] | Train Loss: 0.6849 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6842 | Train Acc: 56.63%\n",
      "Epoch [4/50] | Train Loss: 0.6837 | Train Acc: 56.63%\n",
      "Epoch [5/50] | Train Loss: 0.6825 | Train Acc: 56.63%\n",
      "Epoch [6/50] | Train Loss: 0.6811 | Train Acc: 56.63%\n",
      "Epoch [7/50] | Train Loss: 0.6801 | Train Acc: 56.63%\n",
      "Epoch [8/50] | Train Loss: 0.6771 | Train Acc: 56.63%\n",
      "Epoch [9/50] | Train Loss: 0.6718 | Train Acc: 56.78%\n",
      "Epoch [10/50] | Train Loss: 0.6694 | Train Acc: 59.01%\n",
      "Epoch [11/50] | Train Loss: 0.6620 | Train Acc: 60.64%\n",
      "Epoch [12/50] | Train Loss: 0.6536 | Train Acc: 63.75%\n",
      "Epoch [13/50] | Train Loss: 0.6493 | Train Acc: 62.86%\n",
      "Epoch [14/50] | Train Loss: 0.6482 | Train Acc: 62.79%\n",
      "Epoch [15/50] | Train Loss: 0.6448 | Train Acc: 63.45%\n",
      "Epoch [16/50] | Train Loss: 0.6467 | Train Acc: 61.68%\n",
      "Epoch [17/50] | Train Loss: 0.6445 | Train Acc: 63.16%\n",
      "Epoch [18/50] | Train Loss: 0.6407 | Train Acc: 63.90%\n",
      "Epoch [19/50] | Train Loss: 0.6385 | Train Acc: 64.42%\n",
      "Epoch [20/50] | Train Loss: 0.6362 | Train Acc: 63.16%\n",
      "Epoch [21/50] | Train Loss: 0.6321 | Train Acc: 64.20%\n",
      "Epoch [22/50] | Train Loss: 0.6350 | Train Acc: 63.16%\n",
      "Epoch [23/50] | Train Loss: 0.6351 | Train Acc: 63.45%\n",
      "Epoch [24/50] | Train Loss: 0.6326 | Train Acc: 64.12%\n",
      "Epoch [25/50] | Train Loss: 0.6326 | Train Acc: 64.05%\n",
      "Epoch [26/50] | Train Loss: 0.6306 | Train Acc: 64.12%\n",
      "Epoch [27/50] | Train Loss: 0.6339 | Train Acc: 65.31%\n",
      "Epoch [28/50] | Train Loss: 0.6314 | Train Acc: 64.05%\n",
      "Epoch [29/50] | Train Loss: 0.6295 | Train Acc: 63.97%\n",
      "Epoch [30/50] | Train Loss: 0.6263 | Train Acc: 64.49%\n",
      "Epoch [31/50] | Train Loss: 0.6326 | Train Acc: 63.97%\n",
      "Epoch [32/50] | Train Loss: 0.6312 | Train Acc: 63.83%\n",
      "Epoch [33/50] | Train Loss: 0.6243 | Train Acc: 65.09%\n",
      "Epoch [34/50] | Train Loss: 0.6268 | Train Acc: 65.09%\n",
      "Epoch [35/50] | Train Loss: 0.6283 | Train Acc: 64.20%\n",
      "Epoch [36/50] | Train Loss: 0.6253 | Train Acc: 64.34%\n",
      "Epoch [37/50] | Train Loss: 0.6216 | Train Acc: 65.46%\n",
      "Epoch [38/50] | Train Loss: 0.6214 | Train Acc: 65.68%\n",
      "Epoch [39/50] | Train Loss: 0.6228 | Train Acc: 64.64%\n",
      "Epoch [40/50] | Train Loss: 0.6213 | Train Acc: 64.79%\n",
      "Epoch [41/50] | Train Loss: 0.6149 | Train Acc: 65.60%\n",
      "Epoch [42/50] | Train Loss: 0.6194 | Train Acc: 65.09%\n",
      "Epoch [43/50] | Train Loss: 0.6136 | Train Acc: 66.05%\n",
      "Epoch [44/50] | Train Loss: 0.6128 | Train Acc: 65.38%\n",
      "Epoch [45/50] | Train Loss: 0.6084 | Train Acc: 65.68%\n",
      "Epoch [46/50] | Train Loss: 0.6096 | Train Acc: 64.94%\n",
      "Epoch [47/50] | Train Loss: 0.6072 | Train Acc: 66.05%\n",
      "Epoch [48/50] | Train Loss: 0.6071 | Train Acc: 65.38%\n",
      "Epoch [49/50] | Train Loss: 0.6113 | Train Acc: 65.83%\n",
      "Epoch [50/50] | Train Loss: 0.6065 | Train Acc: 65.53%\n",
      "Fold 2 Results -> Acc: 0.593, Precision: 0.583, Recall: 0.554, F1: 0.530\n",
      "\n",
      "========== Fold 3/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6885 | Train Acc: 55.74%\n",
      "Epoch [2/50] | Train Loss: 0.6848 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6809 | Train Acc: 56.63%\n",
      "Epoch [4/50] | Train Loss: 0.6629 | Train Acc: 58.04%\n",
      "Epoch [5/50] | Train Loss: 0.6414 | Train Acc: 62.94%\n",
      "Epoch [6/50] | Train Loss: 0.6198 | Train Acc: 67.38%\n",
      "Epoch [7/50] | Train Loss: 0.5824 | Train Acc: 71.98%\n",
      "Epoch [8/50] | Train Loss: 0.5461 | Train Acc: 73.68%\n",
      "Epoch [9/50] | Train Loss: 0.5167 | Train Acc: 76.95%\n",
      "Epoch [10/50] | Train Loss: 0.4805 | Train Acc: 78.80%\n",
      "Epoch [11/50] | Train Loss: 0.4497 | Train Acc: 80.95%\n",
      "Epoch [12/50] | Train Loss: 0.4254 | Train Acc: 81.54%\n",
      "Epoch [13/50] | Train Loss: 0.3988 | Train Acc: 83.10%\n",
      "Epoch [14/50] | Train Loss: 0.3745 | Train Acc: 83.84%\n",
      "Epoch [15/50] | Train Loss: 0.3462 | Train Acc: 84.95%\n",
      "Epoch [16/50] | Train Loss: 0.3200 | Train Acc: 86.73%\n",
      "Epoch [17/50] | Train Loss: 0.2942 | Train Acc: 87.10%\n",
      "Epoch [18/50] | Train Loss: 0.2721 | Train Acc: 88.44%\n",
      "Epoch [19/50] | Train Loss: 0.2443 | Train Acc: 90.96%\n",
      "Epoch [20/50] | Train Loss: 0.2226 | Train Acc: 92.14%\n",
      "Epoch [21/50] | Train Loss: 0.1973 | Train Acc: 93.48%\n",
      "Epoch [22/50] | Train Loss: 0.1892 | Train Acc: 93.40%\n",
      "Epoch [23/50] | Train Loss: 0.1661 | Train Acc: 95.18%\n",
      "Epoch [24/50] | Train Loss: 0.1597 | Train Acc: 94.00%\n",
      "Epoch [25/50] | Train Loss: 0.1450 | Train Acc: 95.26%\n",
      "Epoch [26/50] | Train Loss: 0.1314 | Train Acc: 96.00%\n",
      "Epoch [27/50] | Train Loss: 0.1375 | Train Acc: 94.96%\n",
      "Epoch [28/50] | Train Loss: 0.1181 | Train Acc: 95.70%\n",
      "Epoch [29/50] | Train Loss: 0.1183 | Train Acc: 96.00%\n",
      "Epoch [30/50] | Train Loss: 0.0917 | Train Acc: 97.18%\n",
      "Epoch [31/50] | Train Loss: 0.0936 | Train Acc: 96.74%\n",
      "Epoch [32/50] | Train Loss: 0.1065 | Train Acc: 96.59%\n",
      "Epoch [33/50] | Train Loss: 0.0980 | Train Acc: 96.89%\n",
      "Epoch [34/50] | Train Loss: 0.0629 | Train Acc: 98.22%\n",
      "Epoch [35/50] | Train Loss: 0.0796 | Train Acc: 97.41%\n",
      "Epoch [36/50] | Train Loss: 0.0713 | Train Acc: 97.63%\n",
      "Epoch [37/50] | Train Loss: 0.1119 | Train Acc: 97.18%\n",
      "Epoch [38/50] | Train Loss: 0.0478 | Train Acc: 98.67%\n",
      "Epoch [39/50] | Train Loss: 0.0788 | Train Acc: 97.55%\n",
      "Epoch [40/50] | Train Loss: 0.0467 | Train Acc: 98.74%\n",
      "Epoch [41/50] | Train Loss: 0.0386 | Train Acc: 98.89%\n",
      "Epoch [42/50] | Train Loss: 0.0332 | Train Acc: 99.26%\n",
      "Epoch [43/50] | Train Loss: 0.0346 | Train Acc: 99.26%\n",
      "Epoch [44/50] | Train Loss: 0.0281 | Train Acc: 99.33%\n",
      "Epoch [45/50] | Train Loss: 0.0480 | Train Acc: 98.67%\n",
      "Epoch [46/50] | Train Loss: 0.0700 | Train Acc: 98.44%\n",
      "Epoch [47/50] | Train Loss: 0.0320 | Train Acc: 99.48%\n",
      "Epoch [48/50] | Train Loss: 0.0241 | Train Acc: 99.63%\n",
      "Epoch [49/50] | Train Loss: 0.0216 | Train Acc: 99.63%\n",
      "Epoch [50/50] | Train Loss: 0.0555 | Train Acc: 98.67%\n",
      "Fold 3 Results -> Acc: 0.787, Precision: 0.787, Recall: 0.792, F1: 0.786\n",
      "\n",
      "========== Fold 4/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6869 | Train Acc: 56.63%\n",
      "Epoch [2/50] | Train Loss: 0.6860 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6850 | Train Acc: 56.63%\n",
      "Epoch [4/50] | Train Loss: 0.6852 | Train Acc: 56.63%\n",
      "Epoch [5/50] | Train Loss: 0.6834 | Train Acc: 56.63%\n",
      "Epoch [6/50] | Train Loss: 0.6824 | Train Acc: 56.63%\n",
      "Epoch [7/50] | Train Loss: 0.6765 | Train Acc: 56.56%\n",
      "Epoch [8/50] | Train Loss: 0.6595 | Train Acc: 60.56%\n",
      "Epoch [9/50] | Train Loss: 0.6349 | Train Acc: 62.79%\n",
      "Epoch [10/50] | Train Loss: 0.6236 | Train Acc: 66.79%\n",
      "Epoch [11/50] | Train Loss: 0.5980 | Train Acc: 68.57%\n",
      "Epoch [12/50] | Train Loss: 0.5855 | Train Acc: 70.20%\n",
      "Epoch [13/50] | Train Loss: 0.5655 | Train Acc: 72.35%\n",
      "Epoch [14/50] | Train Loss: 0.5416 | Train Acc: 74.28%\n",
      "Epoch [15/50] | Train Loss: 0.5395 | Train Acc: 73.09%\n",
      "Epoch [16/50] | Train Loss: 0.5191 | Train Acc: 75.54%\n",
      "Epoch [17/50] | Train Loss: 0.4980 | Train Acc: 77.46%\n",
      "Epoch [18/50] | Train Loss: 0.4543 | Train Acc: 79.84%\n",
      "Epoch [19/50] | Train Loss: 0.4467 | Train Acc: 80.13%\n",
      "Epoch [20/50] | Train Loss: 0.4240 | Train Acc: 80.36%\n",
      "Epoch [21/50] | Train Loss: 0.3865 | Train Acc: 82.13%\n",
      "Epoch [22/50] | Train Loss: 0.3683 | Train Acc: 84.06%\n",
      "Epoch [23/50] | Train Loss: 0.3459 | Train Acc: 85.47%\n",
      "Epoch [24/50] | Train Loss: 0.3154 | Train Acc: 87.10%\n",
      "Epoch [25/50] | Train Loss: 0.2905 | Train Acc: 88.14%\n",
      "Epoch [26/50] | Train Loss: 0.2753 | Train Acc: 89.47%\n",
      "Epoch [27/50] | Train Loss: 0.2573 | Train Acc: 90.07%\n",
      "Epoch [28/50] | Train Loss: 0.2274 | Train Acc: 91.48%\n",
      "Epoch [29/50] | Train Loss: 0.2163 | Train Acc: 91.48%\n",
      "Epoch [30/50] | Train Loss: 0.1928 | Train Acc: 93.11%\n",
      "Epoch [31/50] | Train Loss: 0.1721 | Train Acc: 94.07%\n",
      "Epoch [32/50] | Train Loss: 0.1577 | Train Acc: 93.85%\n",
      "Epoch [33/50] | Train Loss: 0.1436 | Train Acc: 95.33%\n",
      "Epoch [34/50] | Train Loss: 0.1351 | Train Acc: 95.77%\n",
      "Epoch [35/50] | Train Loss: 0.1349 | Train Acc: 95.92%\n",
      "Epoch [36/50] | Train Loss: 0.1104 | Train Acc: 96.52%\n",
      "Epoch [37/50] | Train Loss: 0.0974 | Train Acc: 97.41%\n",
      "Epoch [38/50] | Train Loss: 0.0791 | Train Acc: 97.18%\n",
      "Epoch [39/50] | Train Loss: 0.0648 | Train Acc: 98.15%\n",
      "Epoch [40/50] | Train Loss: 0.0804 | Train Acc: 97.63%\n",
      "Epoch [41/50] | Train Loss: 0.0566 | Train Acc: 98.37%\n",
      "Epoch [42/50] | Train Loss: 0.0609 | Train Acc: 98.30%\n",
      "Epoch [43/50] | Train Loss: 0.0400 | Train Acc: 98.89%\n",
      "Epoch [44/50] | Train Loss: 0.0425 | Train Acc: 99.11%\n",
      "Epoch [45/50] | Train Loss: 0.0322 | Train Acc: 99.11%\n",
      "Epoch [46/50] | Train Loss: 0.0554 | Train Acc: 98.00%\n",
      "Epoch [47/50] | Train Loss: 0.0624 | Train Acc: 98.52%\n",
      "Epoch [48/50] | Train Loss: 0.0399 | Train Acc: 99.11%\n",
      "Epoch [49/50] | Train Loss: 0.0277 | Train Acc: 99.56%\n",
      "Epoch [50/50] | Train Loss: 0.0153 | Train Acc: 99.78%\n",
      "Fold 4 Results -> Acc: 0.867, Precision: 0.876, Recall: 0.855, F1: 0.861\n",
      "\n",
      "========== Fold 5/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6859 | Train Acc: 56.63%\n",
      "Epoch [2/50] | Train Loss: 0.6850 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6848 | Train Acc: 56.63%\n",
      "Epoch [4/50] | Train Loss: 0.6848 | Train Acc: 56.63%\n",
      "Epoch [5/50] | Train Loss: 0.6847 | Train Acc: 56.63%\n",
      "Epoch [6/50] | Train Loss: 0.6821 | Train Acc: 56.63%\n",
      "Epoch [7/50] | Train Loss: 0.6826 | Train Acc: 56.63%\n",
      "Epoch [8/50] | Train Loss: 0.6489 | Train Acc: 59.08%\n",
      "Epoch [9/50] | Train Loss: 0.6130 | Train Acc: 67.01%\n",
      "Epoch [10/50] | Train Loss: 0.5802 | Train Acc: 71.16%\n",
      "Epoch [11/50] | Train Loss: 0.5550 | Train Acc: 72.05%\n",
      "Epoch [12/50] | Train Loss: 0.5276 | Train Acc: 75.09%\n",
      "Epoch [13/50] | Train Loss: 0.5059 | Train Acc: 76.13%\n",
      "Epoch [14/50] | Train Loss: 0.4828 | Train Acc: 76.65%\n",
      "Epoch [15/50] | Train Loss: 0.4650 | Train Acc: 78.50%\n",
      "Epoch [16/50] | Train Loss: 0.4373 | Train Acc: 79.91%\n",
      "Epoch [17/50] | Train Loss: 0.4133 | Train Acc: 80.87%\n",
      "Epoch [18/50] | Train Loss: 0.3936 | Train Acc: 81.47%\n",
      "Epoch [19/50] | Train Loss: 0.3910 | Train Acc: 80.43%\n",
      "Epoch [20/50] | Train Loss: 0.3383 | Train Acc: 85.03%\n",
      "Epoch [21/50] | Train Loss: 0.3035 | Train Acc: 87.77%\n",
      "Epoch [22/50] | Train Loss: 0.2719 | Train Acc: 88.51%\n",
      "Epoch [23/50] | Train Loss: 0.2467 | Train Acc: 90.14%\n",
      "Epoch [24/50] | Train Loss: 0.2165 | Train Acc: 91.70%\n",
      "Epoch [25/50] | Train Loss: 0.1987 | Train Acc: 92.07%\n",
      "Epoch [26/50] | Train Loss: 0.1716 | Train Acc: 94.22%\n",
      "Epoch [27/50] | Train Loss: 0.1547 | Train Acc: 94.96%\n",
      "Epoch [28/50] | Train Loss: 0.1345 | Train Acc: 95.33%\n",
      "Epoch [29/50] | Train Loss: 0.1206 | Train Acc: 96.44%\n",
      "Epoch [30/50] | Train Loss: 0.1171 | Train Acc: 95.85%\n",
      "Epoch [31/50] | Train Loss: 0.0915 | Train Acc: 97.78%\n",
      "Epoch [32/50] | Train Loss: 0.0915 | Train Acc: 97.03%\n",
      "Epoch [33/50] | Train Loss: 0.0889 | Train Acc: 97.18%\n",
      "Epoch [34/50] | Train Loss: 0.0830 | Train Acc: 97.41%\n",
      "Epoch [35/50] | Train Loss: 0.0732 | Train Acc: 97.85%\n",
      "Epoch [36/50] | Train Loss: 0.0497 | Train Acc: 98.96%\n",
      "Epoch [37/50] | Train Loss: 0.0553 | Train Acc: 98.44%\n",
      "Epoch [38/50] | Train Loss: 0.0657 | Train Acc: 98.44%\n",
      "Epoch [39/50] | Train Loss: 0.0590 | Train Acc: 98.37%\n",
      "Epoch [40/50] | Train Loss: 0.0589 | Train Acc: 98.37%\n",
      "Epoch [41/50] | Train Loss: 0.0380 | Train Acc: 99.26%\n",
      "Epoch [42/50] | Train Loss: 0.0345 | Train Acc: 99.26%\n",
      "Epoch [43/50] | Train Loss: 0.0340 | Train Acc: 99.33%\n",
      "Epoch [44/50] | Train Loss: 0.0292 | Train Acc: 99.48%\n",
      "Epoch [45/50] | Train Loss: 0.0287 | Train Acc: 99.48%\n",
      "Epoch [46/50] | Train Loss: 0.0280 | Train Acc: 99.48%\n",
      "Epoch [47/50] | Train Loss: 0.0271 | Train Acc: 99.48%\n",
      "Epoch [48/50] | Train Loss: 0.0272 | Train Acc: 99.48%\n",
      "Epoch [49/50] | Train Loss: 0.1289 | Train Acc: 97.18%\n",
      "Epoch [50/50] | Train Loss: 0.0541 | Train Acc: 98.59%\n",
      "Fold 5 Results -> Acc: 0.773, Precision: 0.772, Recall: 0.776, F1: 0.772\n",
      "\n",
      "========== Fold 6/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6898 | Train Acc: 55.30%\n",
      "Epoch [2/50] | Train Loss: 0.6790 | Train Acc: 56.71%\n",
      "Epoch [3/50] | Train Loss: 0.6558 | Train Acc: 60.71%\n",
      "Epoch [4/50] | Train Loss: 0.6200 | Train Acc: 67.75%\n",
      "Epoch [5/50] | Train Loss: 0.5932 | Train Acc: 69.16%\n",
      "Epoch [6/50] | Train Loss: 0.5669 | Train Acc: 72.72%\n",
      "Epoch [7/50] | Train Loss: 0.5337 | Train Acc: 74.35%\n",
      "Epoch [8/50] | Train Loss: 0.5047 | Train Acc: 75.76%\n",
      "Epoch [9/50] | Train Loss: 0.4632 | Train Acc: 78.58%\n",
      "Epoch [10/50] | Train Loss: 0.4296 | Train Acc: 79.47%\n",
      "Epoch [11/50] | Train Loss: 0.4125 | Train Acc: 79.54%\n",
      "Epoch [12/50] | Train Loss: 0.3714 | Train Acc: 82.88%\n",
      "Epoch [13/50] | Train Loss: 0.3447 | Train Acc: 84.43%\n",
      "Epoch [14/50] | Train Loss: 0.3275 | Train Acc: 85.54%\n",
      "Epoch [15/50] | Train Loss: 0.3048 | Train Acc: 87.25%\n",
      "Epoch [16/50] | Train Loss: 0.2865 | Train Acc: 88.51%\n",
      "Epoch [17/50] | Train Loss: 0.2678 | Train Acc: 88.88%\n",
      "Epoch [18/50] | Train Loss: 0.2449 | Train Acc: 90.44%\n",
      "Epoch [19/50] | Train Loss: 0.2426 | Train Acc: 90.81%\n",
      "Epoch [20/50] | Train Loss: 0.2074 | Train Acc: 91.77%\n",
      "Epoch [21/50] | Train Loss: 0.1910 | Train Acc: 93.11%\n",
      "Epoch [22/50] | Train Loss: 0.1798 | Train Acc: 93.77%\n",
      "Epoch [23/50] | Train Loss: 0.1565 | Train Acc: 94.66%\n",
      "Epoch [24/50] | Train Loss: 0.1432 | Train Acc: 95.26%\n",
      "Epoch [25/50] | Train Loss: 0.1198 | Train Acc: 96.15%\n",
      "Epoch [26/50] | Train Loss: 0.1146 | Train Acc: 96.07%\n",
      "Epoch [27/50] | Train Loss: 0.1081 | Train Acc: 96.52%\n",
      "Epoch [28/50] | Train Loss: 0.0992 | Train Acc: 96.96%\n",
      "Epoch [29/50] | Train Loss: 0.0771 | Train Acc: 97.85%\n",
      "Epoch [30/50] | Train Loss: 0.1180 | Train Acc: 96.15%\n",
      "Epoch [31/50] | Train Loss: 0.0712 | Train Acc: 98.07%\n",
      "Epoch [32/50] | Train Loss: 0.0943 | Train Acc: 97.18%\n",
      "Epoch [33/50] | Train Loss: 0.0614 | Train Acc: 98.30%\n",
      "Epoch [34/50] | Train Loss: 0.0438 | Train Acc: 98.74%\n",
      "Epoch [35/50] | Train Loss: 0.0381 | Train Acc: 99.18%\n",
      "Epoch [36/50] | Train Loss: 0.0418 | Train Acc: 98.89%\n",
      "Epoch [37/50] | Train Loss: 0.0348 | Train Acc: 99.33%\n",
      "Epoch [38/50] | Train Loss: 0.0923 | Train Acc: 97.18%\n",
      "Epoch [39/50] | Train Loss: 0.0438 | Train Acc: 98.96%\n",
      "Epoch [40/50] | Train Loss: 0.0311 | Train Acc: 99.18%\n",
      "Epoch [41/50] | Train Loss: 0.0232 | Train Acc: 99.48%\n",
      "Epoch [42/50] | Train Loss: 0.0194 | Train Acc: 99.56%\n",
      "Epoch [43/50] | Train Loss: 0.0227 | Train Acc: 99.26%\n",
      "Epoch [44/50] | Train Loss: 0.0395 | Train Acc: 98.96%\n",
      "Epoch [45/50] | Train Loss: 0.0159 | Train Acc: 99.78%\n",
      "Epoch [46/50] | Train Loss: 0.0080 | Train Acc: 99.85%\n",
      "Epoch [47/50] | Train Loss: 0.0093 | Train Acc: 99.63%\n",
      "Epoch [48/50] | Train Loss: 0.0047 | Train Acc: 99.85%\n",
      "Epoch [49/50] | Train Loss: 0.0424 | Train Acc: 98.96%\n",
      "Epoch [50/50] | Train Loss: 0.0035 | Train Acc: 99.93%\n",
      "Fold 6 Results -> Acc: 0.773, Precision: 0.775, Recall: 0.760, F1: 0.764\n",
      "\n",
      "========== Fold 7/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6868 | Train Acc: 56.63%\n",
      "Epoch [2/50] | Train Loss: 0.6849 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6813 | Train Acc: 56.63%\n",
      "Epoch [4/50] | Train Loss: 0.6621 | Train Acc: 57.82%\n",
      "Epoch [5/50] | Train Loss: 0.6344 | Train Acc: 65.90%\n",
      "Epoch [6/50] | Train Loss: 0.6043 | Train Acc: 68.79%\n",
      "Epoch [7/50] | Train Loss: 0.5670 | Train Acc: 70.79%\n",
      "Epoch [8/50] | Train Loss: 0.5177 | Train Acc: 75.24%\n",
      "Epoch [9/50] | Train Loss: 0.4609 | Train Acc: 78.43%\n",
      "Epoch [10/50] | Train Loss: 0.4086 | Train Acc: 80.43%\n",
      "Epoch [11/50] | Train Loss: 0.3536 | Train Acc: 84.73%\n",
      "Epoch [12/50] | Train Loss: 0.3243 | Train Acc: 86.88%\n",
      "Epoch [13/50] | Train Loss: 0.2850 | Train Acc: 88.44%\n",
      "Epoch [14/50] | Train Loss: 0.2573 | Train Acc: 89.92%\n",
      "Epoch [15/50] | Train Loss: 0.2350 | Train Acc: 91.25%\n",
      "Epoch [16/50] | Train Loss: 0.2123 | Train Acc: 92.22%\n",
      "Epoch [17/50] | Train Loss: 0.1892 | Train Acc: 93.62%\n",
      "Epoch [18/50] | Train Loss: 0.1677 | Train Acc: 94.59%\n",
      "Epoch [19/50] | Train Loss: 0.1449 | Train Acc: 95.92%\n",
      "Epoch [20/50] | Train Loss: 0.1703 | Train Acc: 94.51%\n",
      "Epoch [21/50] | Train Loss: 0.1168 | Train Acc: 96.66%\n",
      "Epoch [22/50] | Train Loss: 0.1276 | Train Acc: 95.33%\n",
      "Epoch [23/50] | Train Loss: 0.1256 | Train Acc: 96.22%\n",
      "Epoch [24/50] | Train Loss: 0.0992 | Train Acc: 96.74%\n",
      "Epoch [25/50] | Train Loss: 0.0816 | Train Acc: 97.78%\n",
      "Epoch [26/50] | Train Loss: 0.0636 | Train Acc: 98.44%\n",
      "Epoch [27/50] | Train Loss: 0.0467 | Train Acc: 98.96%\n",
      "Epoch [28/50] | Train Loss: 0.0741 | Train Acc: 98.00%\n",
      "Epoch [29/50] | Train Loss: 0.0545 | Train Acc: 98.37%\n",
      "Epoch [30/50] | Train Loss: 0.0407 | Train Acc: 98.96%\n",
      "Epoch [31/50] | Train Loss: 0.0508 | Train Acc: 98.81%\n",
      "Epoch [32/50] | Train Loss: 0.0561 | Train Acc: 98.44%\n",
      "Epoch [33/50] | Train Loss: 0.0433 | Train Acc: 98.81%\n",
      "Epoch [34/50] | Train Loss: 0.0203 | Train Acc: 99.70%\n",
      "Epoch [35/50] | Train Loss: 0.0179 | Train Acc: 99.56%\n",
      "Epoch [36/50] | Train Loss: 0.0248 | Train Acc: 99.48%\n",
      "Epoch [37/50] | Train Loss: 0.0091 | Train Acc: 99.93%\n",
      "Epoch [38/50] | Train Loss: 0.0341 | Train Acc: 99.26%\n",
      "Epoch [39/50] | Train Loss: 0.0416 | Train Acc: 98.96%\n",
      "Epoch [40/50] | Train Loss: 0.0327 | Train Acc: 99.26%\n",
      "Epoch [41/50] | Train Loss: 0.0189 | Train Acc: 99.56%\n",
      "Epoch [42/50] | Train Loss: 0.0083 | Train Acc: 99.93%\n",
      "Epoch [43/50] | Train Loss: 0.0064 | Train Acc: 99.93%\n",
      "Epoch [44/50] | Train Loss: 0.0060 | Train Acc: 99.93%\n",
      "Epoch [45/50] | Train Loss: 0.0054 | Train Acc: 99.93%\n",
      "Epoch [46/50] | Train Loss: 0.0053 | Train Acc: 99.93%\n",
      "Epoch [47/50] | Train Loss: 0.0050 | Train Acc: 99.93%\n",
      "Epoch [48/50] | Train Loss: 0.0862 | Train Acc: 97.63%\n",
      "Epoch [49/50] | Train Loss: 0.0368 | Train Acc: 99.04%\n",
      "Epoch [50/50] | Train Loss: 0.0171 | Train Acc: 99.56%\n",
      "Fold 7 Results -> Acc: 0.867, Precision: 0.864, Recall: 0.868, F1: 0.865\n",
      "\n",
      "========== Fold 8/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6871 | Train Acc: 55.74%\n",
      "Epoch [2/50] | Train Loss: 0.6765 | Train Acc: 56.86%\n",
      "Epoch [3/50] | Train Loss: 0.6456 | Train Acc: 61.53%\n",
      "Epoch [4/50] | Train Loss: 0.6155 | Train Acc: 65.97%\n",
      "Epoch [5/50] | Train Loss: 0.5875 | Train Acc: 70.05%\n",
      "Epoch [6/50] | Train Loss: 0.5576 | Train Acc: 72.87%\n",
      "Epoch [7/50] | Train Loss: 0.5383 | Train Acc: 72.28%\n",
      "Epoch [8/50] | Train Loss: 0.5171 | Train Acc: 74.94%\n",
      "Epoch [9/50] | Train Loss: 0.4954 | Train Acc: 76.20%\n",
      "Epoch [10/50] | Train Loss: 0.4802 | Train Acc: 76.28%\n",
      "Epoch [11/50] | Train Loss: 0.4616 | Train Acc: 78.58%\n",
      "Epoch [12/50] | Train Loss: 0.4300 | Train Acc: 80.43%\n",
      "Epoch [13/50] | Train Loss: 0.4369 | Train Acc: 79.84%\n",
      "Epoch [14/50] | Train Loss: 0.4118 | Train Acc: 81.32%\n",
      "Epoch [15/50] | Train Loss: 0.3887 | Train Acc: 82.80%\n",
      "Epoch [16/50] | Train Loss: 0.3581 | Train Acc: 85.62%\n",
      "Epoch [17/50] | Train Loss: 0.3279 | Train Acc: 86.43%\n",
      "Epoch [18/50] | Train Loss: 0.3275 | Train Acc: 86.66%\n",
      "Epoch [19/50] | Train Loss: 0.3024 | Train Acc: 86.81%\n",
      "Epoch [20/50] | Train Loss: 0.3055 | Train Acc: 87.84%\n",
      "Epoch [21/50] | Train Loss: 0.2639 | Train Acc: 89.77%\n",
      "Epoch [22/50] | Train Loss: 0.2518 | Train Acc: 89.99%\n",
      "Epoch [23/50] | Train Loss: 0.2382 | Train Acc: 90.81%\n",
      "Epoch [24/50] | Train Loss: 0.2259 | Train Acc: 91.40%\n",
      "Epoch [25/50] | Train Loss: 0.2104 | Train Acc: 91.70%\n",
      "Epoch [26/50] | Train Loss: 0.1926 | Train Acc: 92.51%\n",
      "Epoch [27/50] | Train Loss: 0.1776 | Train Acc: 92.74%\n",
      "Epoch [28/50] | Train Loss: 0.1782 | Train Acc: 93.77%\n",
      "Epoch [29/50] | Train Loss: 0.1728 | Train Acc: 94.07%\n",
      "Epoch [30/50] | Train Loss: 0.1412 | Train Acc: 95.03%\n",
      "Epoch [31/50] | Train Loss: 0.1379 | Train Acc: 95.11%\n",
      "Epoch [32/50] | Train Loss: 0.1353 | Train Acc: 95.70%\n",
      "Epoch [33/50] | Train Loss: 0.1097 | Train Acc: 96.37%\n",
      "Epoch [34/50] | Train Loss: 0.0974 | Train Acc: 96.96%\n",
      "Epoch [35/50] | Train Loss: 0.0901 | Train Acc: 97.26%\n",
      "Epoch [36/50] | Train Loss: 0.0764 | Train Acc: 98.30%\n",
      "Epoch [37/50] | Train Loss: 0.0747 | Train Acc: 97.70%\n",
      "Epoch [38/50] | Train Loss: 0.0629 | Train Acc: 98.44%\n",
      "Epoch [39/50] | Train Loss: 0.0713 | Train Acc: 97.85%\n",
      "Epoch [40/50] | Train Loss: 0.0692 | Train Acc: 98.00%\n",
      "Epoch [41/50] | Train Loss: 0.0436 | Train Acc: 99.04%\n",
      "Epoch [42/50] | Train Loss: 0.0416 | Train Acc: 99.18%\n",
      "Epoch [43/50] | Train Loss: 0.0767 | Train Acc: 98.30%\n",
      "Epoch [44/50] | Train Loss: 0.0476 | Train Acc: 98.89%\n",
      "Epoch [45/50] | Train Loss: 0.0280 | Train Acc: 99.63%\n",
      "Epoch [46/50] | Train Loss: 0.0236 | Train Acc: 99.78%\n",
      "Epoch [47/50] | Train Loss: 0.0260 | Train Acc: 99.56%\n",
      "Epoch [48/50] | Train Loss: 0.0157 | Train Acc: 99.85%\n",
      "Epoch [49/50] | Train Loss: 0.0128 | Train Acc: 99.78%\n",
      "Epoch [50/50] | Train Loss: 0.0101 | Train Acc: 99.85%\n",
      "Fold 8 Results -> Acc: 0.787, Precision: 0.787, Recall: 0.792, F1: 0.786\n",
      "\n",
      "========== Fold 9/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6866 | Train Acc: 56.41%\n",
      "Epoch [2/50] | Train Loss: 0.6852 | Train Acc: 56.63%\n",
      "Epoch [3/50] | Train Loss: 0.6725 | Train Acc: 57.01%\n",
      "Epoch [4/50] | Train Loss: 0.6382 | Train Acc: 63.08%\n",
      "Epoch [5/50] | Train Loss: 0.6011 | Train Acc: 68.12%\n",
      "Epoch [6/50] | Train Loss: 0.5713 | Train Acc: 72.13%\n",
      "Epoch [7/50] | Train Loss: 0.5371 | Train Acc: 72.87%\n",
      "Epoch [8/50] | Train Loss: 0.5030 | Train Acc: 76.13%\n",
      "Epoch [9/50] | Train Loss: 0.4670 | Train Acc: 77.91%\n",
      "Epoch [10/50] | Train Loss: 0.4345 | Train Acc: 79.99%\n",
      "Epoch [11/50] | Train Loss: 0.3987 | Train Acc: 82.73%\n",
      "Epoch [12/50] | Train Loss: 0.3635 | Train Acc: 83.69%\n",
      "Epoch [13/50] | Train Loss: 0.3328 | Train Acc: 84.58%\n",
      "Epoch [14/50] | Train Loss: 0.2979 | Train Acc: 86.88%\n",
      "Epoch [15/50] | Train Loss: 0.2754 | Train Acc: 87.92%\n",
      "Epoch [16/50] | Train Loss: 0.2327 | Train Acc: 90.44%\n",
      "Epoch [17/50] | Train Loss: 0.2031 | Train Acc: 92.44%\n",
      "Epoch [18/50] | Train Loss: 0.1818 | Train Acc: 93.25%\n",
      "Epoch [19/50] | Train Loss: 0.1645 | Train Acc: 93.40%\n",
      "Epoch [20/50] | Train Loss: 0.1234 | Train Acc: 95.11%\n",
      "Epoch [21/50] | Train Loss: 0.1117 | Train Acc: 96.00%\n",
      "Epoch [22/50] | Train Loss: 0.1007 | Train Acc: 96.52%\n",
      "Epoch [23/50] | Train Loss: 0.0835 | Train Acc: 96.89%\n",
      "Epoch [24/50] | Train Loss: 0.0608 | Train Acc: 97.78%\n",
      "Epoch [25/50] | Train Loss: 0.0693 | Train Acc: 97.48%\n",
      "Epoch [26/50] | Train Loss: 0.0629 | Train Acc: 98.07%\n",
      "Epoch [27/50] | Train Loss: 0.0409 | Train Acc: 98.59%\n",
      "Epoch [28/50] | Train Loss: 0.0461 | Train Acc: 98.52%\n",
      "Epoch [29/50] | Train Loss: 0.0578 | Train Acc: 98.00%\n",
      "Epoch [30/50] | Train Loss: 0.0357 | Train Acc: 98.96%\n",
      "Epoch [31/50] | Train Loss: 0.0216 | Train Acc: 99.48%\n",
      "Epoch [32/50] | Train Loss: 0.0342 | Train Acc: 99.18%\n",
      "Epoch [33/50] | Train Loss: 0.0550 | Train Acc: 98.37%\n",
      "Epoch [34/50] | Train Loss: 0.0180 | Train Acc: 99.56%\n",
      "Epoch [35/50] | Train Loss: 0.0189 | Train Acc: 99.63%\n",
      "Epoch [36/50] | Train Loss: 0.0096 | Train Acc: 99.78%\n",
      "Epoch [37/50] | Train Loss: 0.0401 | Train Acc: 98.67%\n",
      "Epoch [38/50] | Train Loss: 0.0160 | Train Acc: 99.63%\n",
      "Epoch [39/50] | Train Loss: 0.0251 | Train Acc: 99.41%\n",
      "Epoch [40/50] | Train Loss: 0.0196 | Train Acc: 99.48%\n",
      "Epoch [41/50] | Train Loss: 0.0084 | Train Acc: 99.85%\n",
      "Epoch [42/50] | Train Loss: 0.0078 | Train Acc: 99.85%\n",
      "Epoch [43/50] | Train Loss: 0.0077 | Train Acc: 99.85%\n",
      "Epoch [44/50] | Train Loss: 0.0074 | Train Acc: 99.85%\n",
      "Epoch [45/50] | Train Loss: 0.0070 | Train Acc: 99.85%\n",
      "Epoch [46/50] | Train Loss: 0.0067 | Train Acc: 99.85%\n",
      "Epoch [47/50] | Train Loss: 0.0064 | Train Acc: 99.85%\n",
      "Epoch [48/50] | Train Loss: 0.0064 | Train Acc: 99.85%\n",
      "Epoch [49/50] | Train Loss: 0.0358 | Train Acc: 99.26%\n",
      "Epoch [50/50] | Train Loss: 0.1052 | Train Acc: 96.89%\n",
      "Fold 9 Results -> Acc: 0.800, Precision: 0.800, Recall: 0.805, F1: 0.799\n",
      "\n",
      "========== Fold 10/10 ==========\n",
      "Detected input size: 2\n",
      "Epoch [1/50] | Train Loss: 0.6876 | Train Acc: 55.78%\n",
      "Epoch [2/50] | Train Loss: 0.6850 | Train Acc: 56.67%\n",
      "Epoch [3/50] | Train Loss: 0.6844 | Train Acc: 56.67%\n",
      "Epoch [4/50] | Train Loss: 0.6811 | Train Acc: 56.59%\n",
      "Epoch [5/50] | Train Loss: 0.6797 | Train Acc: 56.59%\n",
      "Epoch [6/50] | Train Loss: 0.6710 | Train Acc: 58.00%\n",
      "Epoch [7/50] | Train Loss: 0.6554 | Train Acc: 62.37%\n",
      "Epoch [8/50] | Train Loss: 0.6371 | Train Acc: 65.78%\n",
      "Epoch [9/50] | Train Loss: 0.6195 | Train Acc: 66.22%\n",
      "Epoch [10/50] | Train Loss: 0.6066 | Train Acc: 66.22%\n",
      "Epoch [11/50] | Train Loss: 0.5913 | Train Acc: 68.59%\n",
      "Epoch [12/50] | Train Loss: 0.5881 | Train Acc: 69.48%\n",
      "Epoch [13/50] | Train Loss: 0.5621 | Train Acc: 72.74%\n",
      "Epoch [14/50] | Train Loss: 0.5359 | Train Acc: 74.44%\n",
      "Epoch [15/50] | Train Loss: 0.5119 | Train Acc: 77.33%\n",
      "Epoch [16/50] | Train Loss: 0.4735 | Train Acc: 79.04%\n",
      "Epoch [17/50] | Train Loss: 0.4631 | Train Acc: 79.26%\n",
      "Epoch [18/50] | Train Loss: 0.4163 | Train Acc: 81.33%\n",
      "Epoch [19/50] | Train Loss: 0.3812 | Train Acc: 84.00%\n",
      "Epoch [20/50] | Train Loss: 0.3544 | Train Acc: 84.44%\n",
      "Epoch [21/50] | Train Loss: 0.3243 | Train Acc: 86.81%\n",
      "Epoch [22/50] | Train Loss: 0.2829 | Train Acc: 88.52%\n",
      "Epoch [23/50] | Train Loss: 0.2655 | Train Acc: 89.56%\n",
      "Epoch [24/50] | Train Loss: 0.2519 | Train Acc: 89.85%\n",
      "Epoch [25/50] | Train Loss: 0.2407 | Train Acc: 90.59%\n",
      "Epoch [26/50] | Train Loss: 0.2100 | Train Acc: 91.93%\n",
      "Epoch [27/50] | Train Loss: 0.1869 | Train Acc: 93.26%\n",
      "Epoch [28/50] | Train Loss: 0.1743 | Train Acc: 93.56%\n",
      "Epoch [29/50] | Train Loss: 0.1647 | Train Acc: 94.22%\n",
      "Epoch [30/50] | Train Loss: 0.1319 | Train Acc: 95.41%\n",
      "Epoch [31/50] | Train Loss: 0.1106 | Train Acc: 96.07%\n",
      "Epoch [32/50] | Train Loss: 0.0888 | Train Acc: 97.19%\n",
      "Epoch [33/50] | Train Loss: 0.0808 | Train Acc: 97.78%\n",
      "Epoch [34/50] | Train Loss: 0.0898 | Train Acc: 97.11%\n",
      "Epoch [35/50] | Train Loss: 0.0479 | Train Acc: 98.67%\n",
      "Epoch [36/50] | Train Loss: 0.0601 | Train Acc: 98.37%\n",
      "Epoch [37/50] | Train Loss: 0.0557 | Train Acc: 98.44%\n",
      "Epoch [38/50] | Train Loss: 0.1130 | Train Acc: 95.85%\n",
      "Epoch [39/50] | Train Loss: 0.0431 | Train Acc: 98.52%\n",
      "Epoch [40/50] | Train Loss: 0.0251 | Train Acc: 99.41%\n",
      "Epoch [41/50] | Train Loss: 0.0320 | Train Acc: 99.26%\n",
      "Epoch [42/50] | Train Loss: 0.0117 | Train Acc: 99.78%\n",
      "Epoch [43/50] | Train Loss: 0.0074 | Train Acc: 99.85%\n",
      "Epoch [44/50] | Train Loss: 0.0059 | Train Acc: 99.93%\n",
      "Epoch [45/50] | Train Loss: 0.0057 | Train Acc: 99.93%\n",
      "Epoch [46/50] | Train Loss: 0.0056 | Train Acc: 99.93%\n",
      "Epoch [47/50] | Train Loss: 0.0055 | Train Acc: 99.93%\n",
      "Epoch [48/50] | Train Loss: 0.0054 | Train Acc: 99.93%\n",
      "Epoch [49/50] | Train Loss: 0.0054 | Train Acc: 99.93%\n",
      "Epoch [50/50] | Train Loss: 0.0053 | Train Acc: 99.93%\n",
      "Fold 10 Results -> Acc: 0.758, Precision: 0.755, Recall: 0.756, F1: 0.755\n",
      "\n",
      "========== Cross-Validation Results ==========\n",
      "Accuracy:  0.784 ± 0.073\n",
      "Precision: 0.783 ± 0.077\n",
      "Recall:    0.779 ± 0.083\n",
      "F1-score:  0.775 ± 0.089\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ScanpathDataset(\"Scanpaths/all\", \"Raw Data/all\", transform=transform)\n",
    "print(\"Total samples:\", len(dataset))\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Get all labels from dataset for stratification\n",
    "# ------------------------------------------------\n",
    "all_labels = [dataset[i][2] for i in range(len(dataset))]  # assuming (image, seq, label)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Stratified K-Fold setup\n",
    "# ------------------------------------------------\n",
    "num_folds = 10\n",
    "skf = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(np.zeros(len(all_labels)), all_labels)):\n",
    "    print(f\"\\n========== Fold {fold+1}/{num_folds} ==========\")\n",
    "    \n",
    "    # Create DataLoaders for this fold\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_subset, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # infer input_size from one CSV\n",
    "    sample_img, sample_seq, _ = dataset[0]\n",
    "    input_size = sample_seq.shape[1]\n",
    "    print(\"Detected input size:\", input_size)\n",
    "\n",
    "    # Re-initialize the model for each fold\n",
    "    model = VTNet(input_size=input_size, rnn_type='gru').to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Training\n",
    "    # -----------------------------\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for images, sequences, seq_lengths, labels in train_loader:\n",
    "            images, sequences, seq_lengths, labels = (\n",
    "                images.to(device),\n",
    "                sequences.to(device),\n",
    "                seq_lengths.to(device),\n",
    "                labels.to(device)\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, sequences, seq_lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # --- optional: print intermediate training progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Validation\n",
    "    # -----------------------------\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, sequences, seq_lengths, labels in val_loader:\n",
    "            images, sequences, seq_lengths, labels = (\n",
    "                images.to(device),\n",
    "                sequences.to(device),\n",
    "                seq_lengths.to(device),\n",
    "                labels.to(device)\n",
    "            )\n",
    "            outputs = model(images, sequences, seq_lengths)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Compute metrics for this fold\n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    precision = precision_score(all_true, all_preds, average=\"macro\")\n",
    "    recall = recall_score(all_true, all_preds, average=\"macro\")\n",
    "    f1 = f1_score(all_true, all_preds, average=\"macro\")\n",
    "\n",
    "    fold_metrics.append((acc, precision, recall, f1))\n",
    "    print(f\"Fold {fold+1} Results -> Acc: {acc:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1: {f1:.3f}\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Average metrics across folds\n",
    "# ------------------------------------------------\n",
    "fold_metrics = np.array(fold_metrics)\n",
    "mean_metrics = fold_metrics.mean(axis=0)\n",
    "std_metrics = fold_metrics.std(axis=0)\n",
    "\n",
    "print(\"\\n========== Cross-Validation Results ==========\")\n",
    "print(f\"Accuracy:  {mean_metrics[0]:.3f} ± {std_metrics[0]:.3f}\")\n",
    "print(f\"Precision: {mean_metrics[1]:.3f} ± {std_metrics[1]:.3f}\")\n",
    "print(f\"Recall:    {mean_metrics[2]:.3f} ± {std_metrics[2]:.3f}\")\n",
    "print(f\"F1-score:  {mean_metrics[3]:.3f} ± {std_metrics[3]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9489f2b0",
   "metadata": {},
   "source": [
    "## Training Configuration 2: Train/Val/Test Split on DGM Data\n",
    "\n",
    "This section uses a simple 70/15/15 train/validation/test split on data from **Scanpaths/contaminated** and **DGMs v2/3s/all**. This configuration uses different data (3-second DGM sequences) for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163081db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset) \u001b[38;5;241m-\u001b[39m train_size \u001b[38;5;241m-\u001b[39m val_size\n\u001b[0;32m     15\u001b[0m train_ds, val_ds, test_ds \u001b[38;5;241m=\u001b[39m random_split(dataset, [train_size, val_size, test_size])\n\u001b[1;32m---> 17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m     18\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[0;32m     19\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_ds, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n",
      "File \u001b[1;32mc:\\Users\\hapii4u\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 388\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m RandomSampler(dataset, generator\u001b[38;5;241m=\u001b[39mgenerator)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hapii4u\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:156\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((150, 150)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = ScanpathDataset(\"Scanpaths/contaminated\", \"DGMs v2/3s/all\", transform=transform)\n",
    "print(\"Total samples:\", len(dataset))\n",
    "\n",
    "# train/val/test split (70/15/15)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=4, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# infer input_size from one CSV\n",
    "sample_img, sample_seq, _ = dataset[0]\n",
    "input_size = sample_seq.shape[1]\n",
    "print(\"Detected input size:\", input_size)\n",
    "\n",
    "# -----------------------------\n",
    "# Model + training setup\n",
    "# -----------------------------\n",
    "model = VTNet(input_size=input_size, rnn_type='gru').to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# -----------------------------\n",
    "# Training + Validation\n",
    "# -----------------------------\n",
    "for epoch in range(50):\n",
    "    # --- training ---\n",
    "    model.train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for images, sequences, seq_lengths, labels in train_loader:\n",
    "        images, sequences, seq_lengths, labels = (\n",
    "            images.to(device),\n",
    "            sequences.to(device),\n",
    "            seq_lengths.to(device),\n",
    "            labels.to(device)\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, sequences, seq_lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total * 100\n",
    "\n",
    "    # --- validation ---\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    all_labels, all_preds = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, sequences, seq_lengths, labels in val_loader:\n",
    "            images, sequences, seq_lengths, labels = (\n",
    "                images.to(device),\n",
    "                sequences.to(device),\n",
    "                seq_lengths.to(device),\n",
    "                labels.to(device)\n",
    "            )\n",
    "            outputs = model(images, sequences, seq_lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_acc = val_correct / val_total * 100\n",
    "    val_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "    val_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "    val_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f}, Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, Acc: {val_acc:.2f}% | \"\n",
    "          f\"P: {val_precision:.3f}, R: {val_recall:.3f}, F1: {val_f1:.3f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Final Test\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "test_correct, test_total = 0, 0\n",
    "all_labels, all_preds = [], []\n",
    "with torch.no_grad():\n",
    "    for images, sequences, seq_lengths, labels in test_loader:\n",
    "        images, sequences, seq_lengths, labels = (\n",
    "            images.to(device),\n",
    "            sequences.to(device),\n",
    "            seq_lengths.to(device),\n",
    "            labels.to(device)\n",
    "        )\n",
    "        outputs = model(images, sequences, seq_lengths)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_correct += (preds == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_acc = test_correct / test_total * 100\n",
    "test_precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
    "test_recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
    "test_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "print(\"\\n--- Final Test Results ---\")\n",
    "print(f\"Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Precision: {test_precision:.3f}\")\n",
    "print(f\"Recall: {test_recall:.3f}\")\n",
    "print(f\"F1-score: {test_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09a013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    literate       0.80      0.66      0.73        98\n",
      "  illiterate       0.77      0.88      0.82       128\n",
      "\n",
      "    accuracy                           0.78       226\n",
      "   macro avg       0.79      0.77      0.77       226\n",
      "weighted avg       0.79      0.78      0.78       226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# --- Collect predictions and labels ---\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, sequences, seq_lengths, labels in test_loader:\n",
    "        images, sequences, seq_lengths, labels = (\n",
    "            images.to(device),\n",
    "            sequences.to(device),\n",
    "            seq_lengths.to(device),\n",
    "            labels.to(device)\n",
    "        )\n",
    "\n",
    "        outputs = model(images, sequences, seq_lengths)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "classes = [\"literate\", \"illiterate\"]  # matches label_map: literate=0, illiterate=1\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(classification_report(y_true, y_pred, target_names=classes, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad627ecf",
   "metadata": {},
   "source": [
    "## Model Evaluation: Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62086344",
   "metadata": {},
   "source": [
    "## Model Testing and Debugging\n",
    "\n",
    "The following cells test the model with dummy data to verify the architecture and output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2b7cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m input_size = \u001b[32m2\u001b[39m   \u001b[38;5;66;03m# features per timestep\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# generate dummy inputs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m scan_path = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m time_series = torch.randn(batch_size, seq_len, input_size, device=device, dtype=torch.float32)\n\u001b[32m      8\u001b[39m seq_lengths = torch.tensor([seq_len] * batch_size, dtype=torch.long, device=device)  \u001b[38;5;66;03m# all full-length sequences\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "seq_len = 30     # number of timesteps in your series\n",
    "input_size = 2   # features per timestep\n",
    "\n",
    "# generate dummy inputs\n",
    "scan_path = torch.randn(batch_size, 1, 150, 150, device=device, dtype=torch.float32)\n",
    "time_series = torch.randn(batch_size, seq_len, input_size, device=device, dtype=torch.float32)\n",
    "seq_lengths = torch.tensor([seq_len] * batch_size, dtype=torch.long, device=device)  # all full-length sequences\n",
    "\n",
    "# run forward pass (no hidden needed)\n",
    "output = model(scan_path, time_series, seq_lengths)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "print(\"Output logits:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a594e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VTNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=18496, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=306, out_features=20, bias=True)\n",
      "  (fc3): Linear(in_features=20, out_features=2, bias=True)\n",
      "  (rnn): GRU(2, 256, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
